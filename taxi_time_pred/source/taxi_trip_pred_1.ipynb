{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.linear_model import LinearRegression # Our ML model\n",
    "from sklearn.preprocessing import LabelEncoder # Preprocess to get float\n",
    "import numpy as np # Numpy\n",
    "from geopy.distance import vincenty # To calculate distance\n",
    "from ast import literal_eval # This is to convert string representation of array to actual array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "/usr/local/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
    "  warnings.warn(mesg, RuntimeWarning)\n",
    "'''\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are all columns/features we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TRIP_ID', 'CALL_TYPE', 'ORIGIN_CALL', 'ORIGIN_STAND', 'TAXI_ID',\n",
       "       'TIMESTAMP', 'DAY_TYPE', 'MISSING_DATA', 'POLYLINE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing feature/value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ORIGIN_CALL', 'ORIGIN_STAND'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[df.isnull().any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count per feature/column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TRIP_ID         1710670\n",
       "CALL_TYPE       1710670\n",
       "ORIGIN_CALL      364770\n",
       "ORIGIN_STAND     806579\n",
       "TAXI_ID         1710670\n",
       "TIMESTAMP       1710670\n",
       "DAY_TYPE        1710670\n",
       "MISSING_DATA    1710670\n",
       "POLYLINE        1710670\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see few rows of data .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.MISSING_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TRIP_ID         1710660\n",
       "CALL_TYPE       1710660\n",
       "ORIGIN_CALL      364769\n",
       "ORIGIN_STAND     806576\n",
       "TAXI_ID         1710660\n",
       "TIMESTAMP       1710660\n",
       "DAY_TYPE        1710660\n",
       "MISSING_DATA    1710660\n",
       "POLYLINE        1710660\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(df[df.MISSING_DATA == True].index, inplace=True)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to calculate distance between starting and ending location,\n",
    "# so what I'm gonna do is take POLYLINE column, and split it into multiple\n",
    "# chunks- so that I can load entire column into memory and split it\n",
    "\n",
    "# Convert string list representation to list\n",
    "df['POLYLINE'] = df['POLYLINE'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We need to calculate distance and remove this POLYLINE \n",
    "# Vectorize is fun - https://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.vectorize.html\n",
    "def distance(polyline):\n",
    "    try:\n",
    "        return vincenty(polyline[0], polyline[-1]).miles\n",
    "    except Exception as e:\n",
    "        return float('nan')\n",
    "# Let's see how much time it takes for 1 chunk\n",
    "#dist_1 = v_dist(polyline_chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distance using above method\n",
    "df['DISTANCE'] = df['POLYLINE'].apply(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.225683\n",
      "1    1.927831\n",
      "2    0.206913\n",
      "3    2.371665\n",
      "4    2.841243\n",
      "Name: DISTANCE, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.DISTANCE.head())\n",
    "# Drop distances with \"NaN\"\n",
    "df.drop(df[df.DISTANCE == float('nan')].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate label\n",
    "def trip_time(polyline):\n",
    "    return (len(polyline) - 1) * 15\n",
    "label = df['POLYLINE'].apply(trip_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll (or we can) do fancy stuff like getting hour of day and classify them as \n",
    "# (peak hours, ok hours, easy hour/night time). \n",
    "# Get the day of the week\n",
    "# Get the month of the year\n",
    "# this all can be done with given timestamp\n",
    "df['my_dates'] = pd.to_datetime(df['TIMESTAMP'])\n",
    "df['day_of_week'] = df['my_dates'].dt.dayofweek\n",
    "df['month_of_year'] = df['my_dates'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CALL_TYPE', 'ORIGIN_STAND', 'DAY_TYPE', 'DISTANCE', 'day_of_week',\n",
       "       'month_of_year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop polyline, missing data\n",
    "train = df.drop(['POLYLINE', 'MISSING_DATA', 'ORIGIN_CALL','TAXI_ID', 'TIMESTAMP', 'TRIP_ID', 'my_dates'], 1)\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LabelEncoder\n",
    "train = train.apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, time for training with LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr = lr.fit(train, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test df\n",
    "test_df = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(test_df[test_df.MISSING_DATA == True].index, inplace=True)\n",
    "# I need to calculate distance between starting and ending location,\n",
    "# so what I'm gonna do is take POLYLINE column, and split it into multiple\n",
    "# chunks- so that I can load entire column into memory and split it\n",
    "\n",
    "# Convert string list representation to list\n",
    "test_df['POLYLINE'] = test_df['POLYLINE'].apply(literal_eval)\n",
    "# Get distance\n",
    "test_df['DISTANCE'] = test_df['POLYLINE'].apply(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating time based on math\n",
    "\n",
    "test_df.drop(test_df[test_df.DISTANCE == float('nan')].index, inplace=True)\n",
    "result_math_df = test_df[['TRIP_ID']].copy()\n",
    "test_label = test_df['POLYLINE'].apply(trip_time)\n",
    "result_math_df['TRAVEL_TIME'] = test_label\n",
    "result_math_df.to_csv('result_math_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New columns - day of the week and month of the year\n",
    "test_df['my_dates'] = pd.to_datetime(test_df['TIMESTAMP'])\n",
    "test_df['day_of_week'] = test_df['my_dates'].dt.dayofweek\n",
    "test_df['month_of_year'] = test_df['my_dates'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting time based on Regression technique \n",
    "\n",
    "test = test_df.drop(['POLYLINE', 'MISSING_DATA', 'ORIGIN_CALL','TAXI_ID', 'TIMESTAMP', 'TRIP_ID', 'my_dates'], 1)\n",
    "test = test.apply(LabelEncoder().fit_transform)\n",
    "predictions = lr.predict(test)\n",
    "result_regression = result_math_df[['TRIP_ID']].copy()\n",
    "result_regression['TRAVEL_TIME'] = pd.Series(predictions, index=result_regression.index)\n",
    "result_regression.to_csv('result_regression.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
